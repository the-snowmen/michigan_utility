{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e58d1d8",
   "metadata": {},
   "source": [
    "#Can ignore this, this is to check how many features we are learning: should be two, Hit/Miss for this one\n",
    "\n",
    "import os\n",
    "\n",
    "train_dir = r\"C:\\Users\\MHuang\\OneDrive - Everstream\\Desktop\\MikeDHuang_2024\\Machine Learning\\basedata\\T108\\Train\"\n",
    "validation_dir = r\"C:\\Users\\MHuang\\OneDrive - Everstream\\Desktop\\MikeDHuang_2024\\Machine Learning\\basedata\\T108\\Valid\"\n",
    "\n",
    "#List the subdirectories in the training and validation directories\n",
    "print(\"Training subdirectories:\", os.listdir(train_dir))\n",
    "print(\"Validation subdirectories:\", os.listdir(validation_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257bf99",
   "metadata": {},
   "source": [
    "#You will need this to install all the package(s)\n",
    "\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3a0224-60f3-46d0-bdc4-29d7e720e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual learning start from here\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29504d73-a67c-48f6-945e-396ae24170bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15149 images belonging to 2 classes.\n",
      "Found 5100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize ImageDataGenerator\n",
    "train = ImageDataGenerator(rescale=1/255)          #This turn pixels into number, think of it as a big excel sheet, don't touch\n",
    "validation = ImageDataGenerator(rescale=1/255)     #Computer see everything as number (0,1)\n",
    "\n",
    "# We teach the model what is hit and miss, feedback after each iterator\n",
    "train_iterator = train.flow_from_directory(\n",
    "    r\"C:\\Users\\MHuang\\OneDrive - Everstream\\Desktop\\MikeDHuang_2024\\Machine Learning\\basedata\\T108\\Train\",#TODO: change the path\n",
    "    target_size=(720, 720),    #This just mean we are training with 720x720p pictures, model only identify 720x720 aferward\n",
    "    batch_size=16,             #This is the number of samples we feed into the model at each iteration of the training process.\n",
    "    class_mode='binary'        #Binary: tw classes: Yes/No - 1/0. For this process 0 is Hit(No Miss), 1 is Miss (Yes Miss)\n",
    ")\n",
    "\n",
    "# We give them model a mock test to see how it did, it does learn from each iterator\n",
    "validation_iterator = validation.flow_from_directory(\n",
    "    r\"C:\\Users\\MHuang\\OneDrive - Everstream\\Desktop\\MikeDHuang_2024\\Machine Learning\\basedata\\T108\\Valid\",#TODO: change the path\n",
    "    target_size=(720, 720),    #Resize all images to 720x720 pixels to match the training data\n",
    "    batch_size=16,             #Number of samples to process in each batch during validation\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa0ff4",
   "metadata": {},
   "source": [
    "#Skip this as well, this is to check if 0 is hit or 1 is hit\n",
    "\n",
    "#Print class indices for training data\n",
    "print(\"Class indices for training data:\", train_iterator.class_indices)\n",
    "\n",
    "#Print class indices for validation data\n",
    "print(\"Class indices for validation data:\", validation_iterator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d684a346-fcdb-4b58-a25d-48c29c3eb940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DirectoryIterator to a tf.data.Dataset for training, because previously it keep running out of data???\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_iterator,                                           # Using a lambda function to call the train_iterator\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 720, 720, 3), dtype=tf.float32),   # Defines the shape and type of the image tensors\n",
    "                                                                      # ex. float number: 3.14, 0.001, and -2.5\n",
    "                                                                      # 3 is the color channel (RGB)\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)                # Defines the shape and type of the labels (binary)\n",
    "    )\n",
    ").repeat()                                                            # Repeats the dataset indefinitely, fixed the out of range\n",
    "\n",
    "# Convert the DirectoryIterator to a tf.data.Dataset for validation\n",
    "validation_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: validation_iterator,  # Using a lambda function to call the validation_iterator\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 720, 720, 3), dtype=tf.float32),  # Defines the shape and type of the image tensors \n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)               # Defines the shape and type of the labels (binary)\n",
    "    )\n",
    ").repeat()                                                           # Repeats the dataset indefinitely, fixed the out of range\n",
    "\n",
    "# Calculate the number of steps per epoch (the process of going through the entire dataset) for training\n",
    "steps_per_epoch = train_iterator.samples // train_iterator.batch_size\n",
    "# The total number of training samples divided by the batch size is the number of steps per epoch. ex. 1000 // 100 = 10\n",
    "\n",
    "# Calculate the number of steps per epoch for validation\n",
    "validation_steps = validation_iterator.samples // validation_iterator.batch_size\n",
    "# The total number of validation samples divided by the batch size is the number of validation steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa54ffad-4a2e-47bb-88cc-e154da3705c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2047s\u001b[0m 2s/step - accuracy: 0.7937 - loss: 2.0837 - val_accuracy: 0.9951 - val_loss: 0.0213\n",
      "Epoch 2/40\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2028s\u001b[0m 2s/step - accuracy: 0.9968 - loss: 0.0160 - val_accuracy: 0.9969 - val_loss: 0.0166\n",
      "Epoch 3/40\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2029s\u001b[0m 2s/step - accuracy: 0.9965 - loss: 0.0211 - val_accuracy: 0.7288 - val_loss: 3.1581\n",
      "Epoch 4/40\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2034s\u001b[0m 2s/step - accuracy: 0.9945 - loss: 0.0476 - val_accuracy: 0.9851 - val_loss: 0.1547\n",
      "Epoch 5/40\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2040s\u001b[0m 2s/step - accuracy: 0.9982 - loss: 0.0097 - val_accuracy: 0.9943 - val_loss: 0.0734\n",
      "Epoch 6/40\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2053s\u001b[0m 2s/step - accuracy: 0.9975 - loss: 0.0117 - val_accuracy: 0.9854 - val_loss: 0.4924\n",
      "Epoch 7/40\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2037s\u001b[0m 2s/step - accuracy: 0.9976 - loss: 0.0184 - val_accuracy: 0.9925 - val_loss: 0.0825\n",
      "Epoch 8/40\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2021s\u001b[0m 2s/step - accuracy: 0.9956 - loss: 0.0715 - val_accuracy: 0.9925 - val_loss: 0.0720\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "\n",
    "#Filters extract features from the input image.\n",
    "#Kernel Size determines the size of the region in the input image that the filter looks at to compute value in the feature map.\n",
    "#Pool Size reduces the spatial dimensions of the feature maps, retaining important information to improve model efficiency\n",
    "\n",
    "model = tf.keras.models.Sequential([  # Sequential model, where layers are added sequentially\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(720, 720, 3)),\n",
    "    # First convolutional layer with 16 filters, 3x3 kernel size, and ReLU activation function.\n",
    "    # input_shape is defined as 720x720 with 3 color channels (RGB).\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Max pooling layer with a 2x2 pool size to downsample the feature maps.\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    # Second convolutional layer with 32 filters and 3x3 kernel size.\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Another max pooling layer to further reduce the spatial dimensions.\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Third convolutional layer with 64 filters and 3x3 kernel size.\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Max pooling layer to downsample the feature maps again.\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Flatten the 3D output from the convolutional layers into a 1D vector for the dense layers.\n",
    "\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Fully connected layer with 512 neurons and ReLU activation.\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    # Output layer with 1 neuron for binary classification (Hit/Miss), using sigmoid activation.\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              # RMSprop optimizer with a learning rate of 0.001, think of it as one step at a time, we could up it to 0.002,\n",
    "              # but we will increase the risk of the model became unstable, two step or more at a time vs one step at a time\n",
    "              loss='binary_crossentropy',\n",
    "              # Binary cross-entropy loss function, appropriate for binary classification.\n",
    "              metrics=['accuracy'])\n",
    "              # Tracking accuracy as a metric during training and validation.\n",
    "\n",
    "# Define callbacks to improve training process\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "# EarlyStopping callback to stop training if the validation loss does not improve for 6 epochs (change this if needed).\n",
    "# restore_best_weights=True ensures that the model reverts to the best weights when stopping early.\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_T108_v1_window.keras', monitor='val_loss', save_best_only=True)\n",
    "# ModelCheckpoint to save the best model (based on validation loss) during the training process\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_fit = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,     # Number of steps (batches) to run in each training epoch.\n",
    "    epochs=40,                           # Maximum number of epochs to train the model. (bigger doesn't mean better, as I have\n",
    "                                         # set up early stopping (see above) to prevent overfitting; study the answer instead\n",
    "                                         # of the knowledge/process)\n",
    "    validation_data=validation_dataset,  # Validation data to evaluate the model at the end of each epoch.\n",
    "    validation_steps=validation_steps,   # Number of validation steps (batches) to run after each epoch.\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    "    # Callbacks to control early stopping and save the best model during training.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82a1f5-9576-4bd9-99b0-d1085101f404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
